\section{Introduction}
Sparse MoE systems are attractive because they promise higher effective model
capacity at bounded per-token compute \citep{shazeer2017outrageously,
lepikhin2020gshard,fedus2021switch}. In practice, two issues repeatedly
complicate deployment: routing opacity (learned router logits are hard to audit)
and memory pressure (many experts with expensive full-precision weights).

This work focuses on a different operating point: make routing itself
compression-native and directly measurable. MCQSMoE replaces learned router
logits with reconstruction-error routing, where each expert is a
compressor-reconstructor and selection is based on which experts best
reconstruct the token. It combines this with a shared-anchor expert
parameterization and low-bit deltas, constrained on a row-sphere manifold.
The resulting stack targets three engineering outcomes simultaneously:
\emph{(i)} deterministic routing behavior, \emph{(ii)} memory/computation
efficiency, and \emph{(iii)} auditable decision traces.

\paragraph{What is new in this paper.}
\begin{enumerate}
\item \textbf{Routing mechanism:} error-driven top-k expert selection instead of
learned router logits, with explicit per-token routing audit statistics.
\item \textbf{Parameterization:} manifold-constrained shared-anchor plus
quantized per-expert deltas for compressed expert storage and reconstruction.
\item \textbf{Execution and validation:} grouped expert dispatch and repeated-run
measurement with matched dense baselines and trained-artifact parity checks.
\item \textbf{Evidence boundaries:} explicit separation between proven internal
claims and unproven external-SOTA claims, aligned with technical-report style
discipline \citep{deepseek2024v3,huang2025mhc}.
\end{enumerate}

\paragraph{Why this matters.}
If sparse routing is deterministic, inspectable, and cheaper than matched dense
alternatives under controlled settings, it becomes substantially easier to trust
and iterate in production systems. The paper is therefore not only about
reproducibility mechanics; it is about validating a specific sparse modeling
strategy that can reduce serving cost while keeping behavior diagnosable.
